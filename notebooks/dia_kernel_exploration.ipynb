{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e33567-698e-4d36-b9c3-d13803425820",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = https://lsstdesc.org/assets/img/logo.png width=250 style=\"padding: 10px\"> \n",
    "<b>Testing New DIA Kernel Bases</b> <br>\n",
    "Contact author: Michael Wood-Vasey <br>\n",
    "Last verified to run: 2023-06-05 <br>\n",
    "LSST Science Pipelines version: Weekly 2023_21 <br>\n",
    "Container Size: large <br>\n",
    "Targeted learning level: intermediate <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd41fa-bff0-42af-b1ba-c9eb98a08f7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sets up a interactive stepping through of the tasks to do image subtraction to allow for easier modifications to StarSelector, Kernel bases, and Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46152cfb-4828-4458-bdf2-fa7615f5fb10",
   "metadata": {},
   "source": [
    "Note: This Notebook is written below the PipelineTask level.  Rather is uses individual Tasks directly and reads/writes output products to the butler.  This is pedagogically useful to understand how that works, and pratically helpful in working with the evolving `source_injection` package.  However, this structure is not scalable to larger runs (100+ images).  Such large-scale runs should be done as part of an integrated Task that can be connected and run through the large-scale cluster jobs submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08728c8-e41a-42f5-8bd8-fbfbb21d4229",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. [x] Find set of images that overlap\n",
    "2. [x] Pick one as template, one as science\n",
    "3. [x] Also deepCoadd.  Be able to use either.\n",
    "4. [x] Run subtractions through Tasks\n",
    "5. [x] Run detection and measurement through Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6b5a2-1fde-4dc2-84ee-97260750b278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "import os\n",
    "from typing import Union\n",
    "\n",
    "import astropy.table\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.afw.image\n",
    "from lsst.afw.math import Warper, WarperConfig\n",
    "import lsst.afw.table\n",
    "from lsst.daf.butler import Butler\n",
    "import lsst.geom as geom\n",
    "from lsst.ip.diffim import AlardLuptonSubtractConfig, AlardLuptonSubtractTask\n",
    "from lsst.ip.diffim import GetTemplateConfig, GetTemplateTask\n",
    "from lsst.ip.diffim import DetectAndMeasureConfig, DetectAndMeasureTask\n",
    "import lsst.sphgeom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d5936a-3117-4a89-ac05-ef73bc2d6a1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T19:46:58.345310Z",
     "iopub.status.busy": "2023-06-12T19:46:58.344521Z",
     "iopub.status.idle": "2023-06-12T19:46:58.349007Z",
     "shell.execute_reply": "2023-06-12T19:46:58.348193Z",
     "shell.execute_reply.started": "2023-06-12T19:46:58.345284Z"
    },
    "tags": []
   },
   "source": [
    "Some things we may or may not want to import for overriding or inheriting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abafbcf-5d92-436d-bd72-af7f4e18cf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.pipe.tasks.makeWarp import MakeWarpConfig, MakeWarpTask\n",
    "from lsst.ip.diffim import MakeKernelConfig, MakeKernelTask, PsfMatchConfig, PsfMatchConfigAL, PsfMatchConfigDF\n",
    "from lsst.ip.diffim.subtractImages import _subtractImages\n",
    "from lsst.ip.diffim.utils import evaluateMeanPsfFwhm, getPsfFwhm\n",
    "from lsst.meas.algorithms import SourceDetectionTask, SubtractBackgroundTask\n",
    "from lsst.meas.base import SingleFrameMeasurementTask\n",
    "from lsst.pex.exceptions import InvalidParameterError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa7cac-2dd3-4cc2-9d36-c1002981d08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "afwDisplay.setDefaultBackend('matplotlib')\n",
    "plt.style.use('tableau-colorblind10')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d9a34-2b35-42e6-ba6e-9ce2669a31a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Some helper utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b8e5d-40d7-42d9-aebc-ecd5cecb7992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_image_on_wcs(calexp, figsize=(8, 8), ax=None, x=None, y=None,\n",
    "                           pixel_extent=None, stamp_size=None,\n",
    "                           vmin=-200, vmax=400,\n",
    "                           marker=\"o\", color=\"red\", size=20):\n",
    "    \"\"\"\n",
    "    Show an image with an RA, Dec grid overlaid.  Optionally add markers.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Specifying both pixel_extent and size is undefined.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        plt.subplot(projection=WCS(calexp.getWcs().getFitsMetadata()))\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if stamp_size is not None and x is not None and y is not None:    \n",
    "        half_stamp = stamp_size / 2\n",
    "        # If x and y are of different types, then user should clarify what they wanted\n",
    "        if np.isscalar(x):\n",
    "            first_x = x\n",
    "            first_y = y\n",
    "        else:\n",
    "            first_x = x[0]\n",
    "            first_y = y[0]\n",
    "            \n",
    "        pixel_extent = (int(first_x - half_stamp), int(first_x + half_stamp),\n",
    "                        int(first_y - half_stamp), int(first_y + half_stamp))\n",
    "    if pixel_extent is None:\n",
    "        pixel_extent = (0, calexp.width, 0, calexp.height)\n",
    "\n",
    "    # Image array is y, x.  \n",
    "    # So we select from the image array in [Y_Begin:Y_End, X_Begin:X_End]\n",
    "    # But then `extent` is (X_Begin, X_End, Y_Begin, Y_End)\n",
    "    im = ax.imshow(calexp.image.array[pixel_extent[2]:pixel_extent[3],\n",
    "                                      pixel_extent[0]:pixel_extent[1]],\n",
    "                   cmap=\"gray\", vmin=vmin, vmax=vmax,\n",
    "                   extent=pixel_extent, origin=\"lower\")\n",
    "    ax.grid(color=\"white\", ls=\"solid\")\n",
    "    ax.set_xlabel(\"Right Ascension\")\n",
    "    ax.set_ylabel(\"Declination\")\n",
    "    if x is not None and y is not None:\n",
    "        ax.scatter(x, y, s=size, marker=marker, edgecolor=color, facecolor=\"none\")\n",
    "        ax.set_xlim(pixel_extent[0:2])\n",
    "        ax.set_ylim(pixel_extent[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36519e1e-6d97-4d32-937c-d16d400c19c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_mask_plane(calexp, figsize=(8, 8)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    display = afwDisplay.Display(frame=fig)\n",
    "    display.scale('asinh', 'zscale')\n",
    "    display.setMaskTransparency(80)\n",
    "    display.setMaskPlaneColor('DETECTED', 'blue')\n",
    "    display.mtv(calexp)\n",
    "    plt.show()\n",
    "    \n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff7249-bf1d-4474-82cf-b89a1fbe55b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def htm_from_ra_dec_level(ra, dec, level):\n",
    "    pixelization = lsst.sphgeom.HtmPixelization(level)\n",
    "    htm_id = pixelization.index(\n",
    "        lsst.sphgeom.UnitVector3d(\n",
    "            lsst.sphgeom.LonLat.fromDegrees(ra, dec)\n",
    "        )\n",
    "    )\n",
    "    return htm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664233e-5849-4ca2-ba04-b4fa2162b6a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset_refs_from_htm_list(dataset_type, htm_ids, level, aggregate=\"intersection\"):\n",
    "    hi = htm_ids[0]\n",
    "\n",
    "    # dataset_refs is an iterator, but each query is only a few hundred results,\n",
    "    #   so convert to a list for future convenience\n",
    "    htm_kwargs = {}\n",
    "    htm_kwargs[f\"htm{level}\"] = hi\n",
    "    dataset_refs = list(butler.registry.queryDatasets(dataset_type, dataId={\"band\": band}, **htm_kwargs))\n",
    "    dataset_refs = set(dataset_refs)\n",
    "    \n",
    "    for hi in htm_ids[1:]:\n",
    "        htm_kwargs = {}\n",
    "        htm_kwargs[f\"htm{level}\"] = hi\n",
    "        dr = list(butler.registry.queryDatasets(dataset_type, dataId={\"band\": band}, **htm_kwargs))\n",
    "        if aggregate == \"intersection\":\n",
    "            dataset_refs = dataset_refs.intersection(set(dr))\n",
    "        elif aggregate == \"union\":\n",
    "            dataset_refs = dataset_refs.union(set(dr))\n",
    "        else:\n",
    "            print(\"Aggregation method '{aggregate}' not supported.\")\n",
    "            return\n",
    "        \n",
    "    return list(dataset_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d51062-67f9-4ce5-b0e8-f0e9deb4d487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T16:14:15.228965Z",
     "iopub.status.busy": "2023-06-02T16:14:15.228253Z",
     "iopub.status.idle": "2023-06-02T16:14:15.233334Z",
     "shell.execute_reply": "2023-06-02T16:14:15.232377Z",
     "shell.execute_reply.started": "2023-06-02T16:14:15.228931Z"
    },
    "tags": []
   },
   "source": [
    "## Defining Dataset based on Site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b0dd0-2d54-41d8-a043-0e3ab5c16672",
   "metadata": {},
   "source": [
    "We can run this on either DC2 or HSC by choosing appropriate RA, Dec\n",
    "\n",
    "Currently (2023-05-26) DC2 is only available at the IDF and HSC is only available at the USDF,\n",
    "so we split by site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0462aa-afec-49d0-88d9-04d075cb2ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SITE = \"IDF\"\n",
    "\n",
    "survey_site = {\"USDF\": \"HSC\", \"IDF\": \"DC2\", \"NERSC\": \"DC2\"}\n",
    "repo_site = {\"USDF\": \"/repo/main\", \"IDF\": \"dp02\", \"NERSC\": \"/global/cfs/cdirs/lsst/production/gen3/DC2/Run2.2i/repo\"}\n",
    "collection_site = {\"USDF\": \"HSC/runs/RC2/w_2023_15/DM-38691\", \"IDF\": \"2.2i/runs/DP0.2\", \"NERSC\": \"u/descdm/coadds_Y1_4638\"}\n",
    "\n",
    "ra_dec_survey = {\"HSC\": (150, 2.5), \"DC2\": (55, -30)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2510b-9d8c-4a44-a2c0-7dd27662110c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection = collection_site[SITE]\n",
    "repo_config = repo_site[SITE]\n",
    "\n",
    "user = os.getenv(\"USER\")\n",
    "output_collection = f\"u/{user}/test_dia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea1bd1-83b9-4f48-a824-cee94014583b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "butler = Butler(repo_config, run=output_collection, collections=[output_collection, collection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9269a3-a928-43c1-bd56-2e87e52322ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do a spatial query for calexps using HTM levels following example in 04b_Intermediate_Butler_Queries.ipynb\n",
    "ra, dec = ra_dec_survey[survey_site[SITE]]\n",
    "band = \"i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704e956-b196-4cc8-9bcf-9a4dac30ee3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "level = 20  # the resolution of the HTM grid\n",
    "htm_id = htm_from_ra_dec_level(ra, dec, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac405a8c-98b2-45e6-8fec-3f87d6fbedce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_level = htm_id // 10\n",
    "htm_ids = [parent_level * 10 + i for i in [0, 1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048f6c4-0b4f-45f8-8493-b92aa3b7ac81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "htm_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b03aed-bcd3-441e-bf17-120c8f02f274",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_refs = get_dataset_refs_from_htm_list(\"calexp\", htm_ids, level)\n",
    "\n",
    "# Sort by visitId to get a loose time order\n",
    "ids_visit = [dr.dataId[\"visit\"] for dr in dataset_refs]\n",
    "dataset_refs = [dataset_refs[idx] for idx in np.argsort(ids_visit)]\n",
    "\n",
    "print(dataset_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51bbfa-92e9-4a66-9a74-081286815ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Found {len(list(dataset_refs))} calexps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca2798-dc98-426b-9a89-c32b952dab03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visit_table = butler.get(\"visitTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902d976-a034-47b7-9a77-af9e835f9942",
   "metadata": {},
   "source": [
    "We should find 140 calexps for DC2.  (RA, Dec) = (55, -30)  \n",
    "\n",
    "We should find 44 calexps for HSC COSMOS.  (RA, Dec) = (150, +2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ded5d5-1a4a-4612-8479-fe9a2f4dba2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T14:54:47.776325Z",
     "iopub.status.busy": "2023-05-02T14:54:47.775867Z",
     "iopub.status.idle": "2023-05-02T14:54:47.792118Z",
     "shell.execute_reply": "2023-05-02T14:54:47.791426Z",
     "shell.execute_reply.started": "2023-05-02T14:54:47.776303Z"
    },
    "tags": []
   },
   "source": [
    "# Build template for subtraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25451e67-80c7-424b-8966-f3531c872c53",
   "metadata": {},
   "source": [
    "Also provide a single image template based on calexp[0] in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a432b4-8ca3-4e5f-8304-51dc24e11faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "single_image_template = butler.get(\"calexp\", dataset_refs[0].dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a43f8c-7467-4250-88fa-044c74d31315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T20:39:30.522732Z",
     "iopub.status.busy": "2023-06-12T20:39:30.522162Z",
     "iopub.status.idle": "2023-06-12T20:39:30.528900Z",
     "shell.execute_reply": "2023-06-12T20:39:30.527948Z",
     "shell.execute_reply.started": "2023-06-12T20:39:30.522679Z"
    },
    "tags": []
   },
   "source": [
    "Run subtractions with calexp[1] as science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354e6dd-f99b-417a-af95-7811de40b6b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "science_dr = dataset_refs[1]\n",
    "science = butler.get(\"calexp\", science_dr.dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd061a2-d2c0-4692-9429-036a980ac146",
   "metadata": {},
   "source": [
    "### Get a template from the deepCoadd\n",
    "Here we get a template from the (tract, patch) deepCoadd reassembled to be continous across calexp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8992e85-9a0a-42f3-b1e3-587b6af22b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_map = butler.get(\"skyMap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdbf4f0-49ba-48e6-8a38-c09ebc8477ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_template_task_config = GetTemplateConfig()\n",
    "get_template_task = GetTemplateTask(config=get_template_task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e452a132-3a92-47ef-b2e9-71929d0b79ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bigger_level = 9\n",
    "bigger_htm_id = htm_from_ra_dec_level(ra, dec, level=bigger_level)\n",
    "\n",
    "coadd_exposure_refs = get_dataset_refs_from_htm_list(\"deepCoadd\", [bigger_htm_id], level=bigger_level, aggregate=\"union\")\n",
    "coadd_exposure_deferred_dataset_handles = [butler.getDeferred(dr) for dr in coadd_exposure_refs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaac140-528b-4ff7-a9b6-47e64d9ae093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coadd_exposure_deferred_dataset_handles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf620fce-be38-4b4e-9173-6b45f812fd66",
   "metadata": {},
   "source": [
    "Check that we're close to original RA, Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351b2b2-dad6-4c63-bd01-e45d8e5e246f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "science.getWcs().pixelToSky(science.getBBox().getCenter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf73d5-ade1-40c2-9a50-b2328066675b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = {\"coaddExposures\" : coadd_exposure_deferred_dataset_handles,\n",
    "          \"bbox\": science.getBBox(),\n",
    "          \"skyMap\": sky_map,\n",
    "          \"wcs\": science.getWcs(),\n",
    "          \"visitInfo\": science.visitInfo,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935e25a-70ee-442e-9683-9514210063e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = get_template_task.getOverlappingExposures(inputs)\n",
    "coadd_exposures = results.coaddExposures\n",
    "data_ids = results.dataIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d309c-57c2-409f-ace2-ec83877f0384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deep_coadd_template = get_template_task.run(coadd_exposures, inputs[\"bbox\"], inputs[\"wcs\"], data_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576892c-b5b8-4bb1-aa38-e054642acbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do I need to iterate or could I just del coadd_exposures with the same effect?\n",
    "for ce in coadd_exposures:\n",
    "    del ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68354c-1865-4e9f-9ab6-b70739fb7829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = deep_coadd_template.template\n",
    "\n",
    "figsize = (12, 6)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=WCS(template.getWcs().getFitsMetadata()))\n",
    "show_image_on_wcs(template, vmin=-2, vmax=+4, ax=ax1)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection=WCS(science.getWcs().getFitsMetadata()))\n",
    "show_image_on_wcs(science, vmin=-200, vmax=+400, ax=ax2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb0724-752e-4c60-a9a0-d93337cec13f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T20:27:29.648116Z",
     "iopub.status.busy": "2023-06-02T20:27:29.647429Z",
     "iopub.status.idle": "2023-06-02T20:27:29.651340Z",
     "shell.execute_reply": "2023-06-02T20:27:29.650651Z",
     "shell.execute_reply.started": "2023-06-02T20:27:29.648086Z"
    },
    "tags": []
   },
   "source": [
    "## Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92263b0-2c7c-4bcb-af42-e9b8ed018ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def warp(science, template):\n",
    "    \"Warp input template image to WCS and Bounding Box of the science image.\"\n",
    "    warper_config = WarperConfig()\n",
    "    warper = Warper.fromConfig(warper_config)\n",
    "\n",
    "    science_wcs = science.getWcs()\n",
    "    science_bbox = science.getBBox()\n",
    "    \n",
    "    warped_template = warper.warpExposure(science_wcs, template, destBBox=science_bbox)\n",
    "    # Add PSF.  I think doing this directly without warping is wrong.\n",
    "    # At least the x,y mapping should be updated\n",
    "    warped_template.setPsf(template.getPsf())\n",
    "    \n",
    "    return warped_template\n",
    "\n",
    "\n",
    "def subtract(science, template, source_catalog, task=None, config=None):\n",
    "    # https://github.com/lsst/ip_diffim/blob/main/python/lsst/ip/diffim/subtractImages.py#L196\n",
    "    if config is None and task is None:\n",
    "        config = AlardLuptonSubtractConfig()\n",
    "    if task is None:\n",
    "        task = AlardLuptonSubtractTask(config=config)\n",
    "    # Star Selection is done here:\n",
    "    #   https://github.com/lsst/ip_diffim/blob/main/python/lsst/ip/diffim/subtractImages.py#L603\n",
    "\n",
    "    warped_template = warp(science, template)\n",
    "    \n",
    "    subtraction = task.run(warped_template, science, source_catalog)\n",
    "    \n",
    "    return subtraction\n",
    "\n",
    "\n",
    "def detect(science, subtraction):\n",
    "    # Run detection on subtraction\n",
    "    detect_and_measure_config = DetectAndMeasureConfig()\n",
    "    detect_and_measure_task = DetectAndMeasureTask(config=detect_and_measure_config)\n",
    "\n",
    "    detect_and_measure = detect_and_measure_task.run(science,\n",
    "                                                     subtraction.matchedTemplate,\n",
    "                                                     subtraction.difference)\n",
    "\n",
    "    return detect_and_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff6cc43-9ef0-4f87-9eca-e43b28f8846c",
   "metadata": {},
   "source": [
    "## Provide a modified makeKernel\n",
    "\n",
    "We can inherit from and then modify methods of the MakeKernelTask to test ideas for improvements.\n",
    "\n",
    "The kernel used by AlardLuptonSubtractTask is a configurable option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489860f0-d1b0-49f9-9409-25e6c789d03a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/lsst/ip_diffim/blob/w.2023.07/python/lsst/ip/diffim/makeKernel.py#L45\n",
    "\n",
    "class ModifiedMakeKernelConfig(MakeKernelConfig):\n",
    "    \"\"\"Stub inherited class to let room for future configuration passing\"\"\"\n",
    "    # If you wanted to create a new config parameter to pass to the task:\n",
    "    # foo = lsst.pex.config.ConfigChoiceField(doc=\"foo threshold\", dtype=float, default=1.0)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f25aee-c9e1-459b-96d0-10a709332b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModifiedMakeKernelTask(MakeKernelTask):\n",
    "    \"\"\"Construct a kernel for PSF matching two exposures\n",
    "\n",
    "    This Modified class is an example for showing to to create your own kernel-solving class.\n",
    "    \"\"\"\n",
    "\n",
    "    ConfigClass = ModifiedMakeKernelConfig\n",
    "    _DefaultName = \"makeModifiedKernel\"\n",
    "\n",
    "    # This is the routine we might want to replace wtih our own ideas\n",
    "    # about finding a good convolution kernel\n",
    "    # Needs to return an lsst.afw.math.LinearCombinationKernel\n",
    "    # Original\n",
    "    #  https://github.com/lsst/ip_diffim/blob/main/python/lsst/ip/diffim/makeKernel.py#L108\n",
    "    def run(self, template, science, kernelSources, preconvolved=False):\n",
    "        \"\"\"Solve for the kernel and background model that best match two\n",
    "        Exposures evaluated at the given source locations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        template : `lsst.afw.image.Exposure`\n",
    "            Exposure that will be convolved.\n",
    "        science : `lsst.afw.image.Exposure`\n",
    "            The exposure that will be matched.\n",
    "        kernelSources : `list` of `dict`\n",
    "            A list of dicts having a \"source\" and \"footprint\"\n",
    "            field for the Sources deemed to be appropriate for Psf\n",
    "            matching. Can be the output from ``selectKernelSources``.\n",
    "        preconvolved : `bool`, optional\n",
    "            Was the science image convolved with its own PSF?\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        results : `lsst.pipe.base.Struct`\n",
    "\n",
    "            ``psfMatchingKernel`` : `lsst.afw.math.LinearCombinationKernel`\n",
    "                Spatially varying Psf-matching kernel.\n",
    "            ``backgroundModel``  : `lsst.afw.math.Function2D`\n",
    "                Spatially varying background-matching function.\n",
    "        \"\"\"\n",
    "        # Just debugging that we're really running this modified task\n",
    "        self.log.info(\"Running Modified Make Kernel Task\")\n",
    "\n",
    "        kernelCellSet = self._buildCellSet(\n",
    "            template.maskedImage, science.maskedImage, kernelSources\n",
    "        )\n",
    "        # Calling getPsfFwhm on template.psf fails on some rare occasions when\n",
    "        # the template has no input exposures at the average position of the\n",
    "        # stars. So we try getPsfFwhm first on template, and if that fails we\n",
    "        # evaluate the PSF on a grid specified by fwhmExposure* fields.\n",
    "        # To keep consistent definitions for PSF size on the template and\n",
    "        # science images, we use the same method for both.\n",
    "        try:\n",
    "            templateFwhmPix = getPsfFwhm(template.psf)\n",
    "            scienceFwhmPix = getPsfFwhm(science.psf)\n",
    "        except InvalidParameterError:\n",
    "            self.log.debug(\n",
    "                \"Unable to evaluate PSF at the average position. \"\n",
    "                \"Evaluting PSF on a grid of points.\"\n",
    "            )\n",
    "            templateFwhmPix = evaluateMeanPsfFwhm(\n",
    "                template,\n",
    "                fwhmExposureBuffer=self.config.fwhmExposureBuffer,\n",
    "                fwhmExposureGrid=self.config.fwhmExposureGrid,\n",
    "            )\n",
    "            scienceFwhmPix = evaluateMeanPsfFwhm(\n",
    "                science,\n",
    "                fwhmExposureBuffer=self.config.fwhmExposureBuffer,\n",
    "                fwhmExposureGrid=self.config.fwhmExposureGrid,\n",
    "            )\n",
    "\n",
    "        if preconvolved:\n",
    "            scienceFwhmPix *= np.sqrt(2)\n",
    "\n",
    "        ### THESE LINES ARE PROBABLY WHERE YOU WANT TO CHANGE: BEGIN ###\n",
    "        basisList = self.makeKernelBasisList(\n",
    "            templateFwhmPix, scienceFwhmPix, metadata=self.metadata\n",
    "        )\n",
    "        spatialSolution, psfMatchingKernel, backgroundModel = self._solve(\n",
    "            kernelCellSet, basisList\n",
    "        )\n",
    "        ### END: THESE LINES ARE PROBABLY WHERE YOU WANT TO CHANGE\n",
    "\n",
    "        return lsst.pipe.base.Struct(\n",
    "            psfMatchingKernel=psfMatchingKernel,\n",
    "            backgroundModel=backgroundModel,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9281b-325b-4cd3-ba5d-d843b21424f1",
   "metadata": {},
   "source": [
    "If we want to modify the run... method of the subtraction task itself, we would subclass AlardLuptonSubtractTask and modify the `run...` method.  Here we just pick \"Modified\" to be generic, but if one had a specific name, that would be good too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d2b8d-7830-4901-a92a-bffca21acb7b",
   "metadata": {},
   "source": [
    "Try importing calculation from al-algorithm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64965e6d-81cf-41f8-8b7d-45fa6a8f8bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.polynomial.polynomial import polyval2d\n",
    "from numpy.polynomial.chebyshev import chebval2d\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.signal\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "def compute_xy_grids(x_len, y_len):\n",
    "    x = np.arange(-x_len // 2 + 1, x_len // 2 + 1, 1, dtype=np.float32)\n",
    "    y = np.arange(-y_len // 2 + 1, y_len // 2 + 1, 1, dtype=np.float32)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def gaussian2d(xx, yy, m=[0.0, 0.0], cov=[[1, 0], [0, 1]]):\n",
    "    grid = np.dstack((xx, yy))\n",
    "    var = multivariate_normal(mean=m, cov=cov)\n",
    "    return var.pdf(grid)\n",
    "\n",
    "\n",
    "def chebGauss2d(xx, yy, gauss_cov, poly_deg):\n",
    "    # compute Gaussian\n",
    "    gau = gaussian2d(xx, yy, cov=gauss_cov)\n",
    "    # compute Chebyshev\n",
    "    x_deg, y_deg = poly_deg[0], poly_deg[1]\n",
    "    coef_x = np.zeros(x_deg + 1)\n",
    "    coef_x[x_deg] = 1\n",
    "    coef_y = np.zeros(y_deg + 1)\n",
    "    coef_y[y_deg] = 1\n",
    "    coefs = np.outer(coef_x, coef_y)\n",
    "    cheb = chebval2d(xx, yy, c=coefs)\n",
    "    return cheb * gau\n",
    "\n",
    "\n",
    "def compute_kernel_bases(kernel_size, sig_ls, poly_deg_ls):\n",
    "    xx, yy = compute_xy_grids(kernel_size, kernel_size)\n",
    "    kernel_bases = []\n",
    "    for id_x, x_sig in enumerate(sig_ls):\n",
    "        for id_y, y_sig in enumerate(sig_ls):\n",
    "            for x_deg in range(poly_deg_ls[id_x] + 1):\n",
    "                for y_deg in range(poly_deg_ls[id_y] + 1):\n",
    "                    gauss_cov = [[x_sig, 0.0], [0.0, y_sig]]\n",
    "                    poly_deg = (x_deg, y_deg)\n",
    "                    kernel_bases.append(chebGauss2d(xx, yy, gauss_cov, poly_deg))\n",
    "    return kernel_bases\n",
    "\n",
    "\n",
    "def compute_base_image_matrix(template, kernel_bases):\n",
    "    base_im_ls = []\n",
    "    for basis in kernel_bases:\n",
    "        base_im = scipy.signal.fftconvolve(template, basis, mode=\"same\")\n",
    "        base_im_ls.append(base_im.flatten())\n",
    "    base_image_matrix = np.vstack(base_im_ls).T\n",
    "    return base_image_matrix\n",
    "\n",
    "\n",
    "def compute_spatial_image_matrix(xx, yy, spatial_deg, verbose=False):\n",
    "    spatial_image_ls = []\n",
    "    for x_deg in range(spatial_deg + 1):\n",
    "        for y_deg in range(spatial_deg - x_deg + 1):\n",
    "            if verbose:\n",
    "                print(x_deg, y_deg)\n",
    "            coef_x = np.zeros(x_deg + 1)\n",
    "            coef_x[x_deg] = 1\n",
    "            coef_y = np.zeros(y_deg + 1)\n",
    "            coef_y[y_deg] = 1\n",
    "            coefs = np.outer(coef_x, coef_y)\n",
    "            spatial_image = polyval2d(xx, yy, c=coefs)\n",
    "            spatial_image_ls.append(spatial_image.flatten())\n",
    "    spatial_image_matrix = np.vstack(spatial_image_ls).T\n",
    "    return spatial_image_matrix\n",
    "\n",
    "\n",
    "def compute_base_spatial_image_matrix(base_image_matrix, kernel_spatial_image_matrix):\n",
    "    base_spatial_vec_ls = []\n",
    "    for i in range(base_image_matrix.shape[1]):\n",
    "        base_vec = base_image_matrix[:, i]\n",
    "        for j in range(kernel_spatial_image_matrix.shape[1]):\n",
    "            kernel_spatial_vec = kernel_spatial_image_matrix[:, j]\n",
    "            base_spatial_vec = base_vec * kernel_spatial_vec\n",
    "            base_spatial_vec_ls.append(base_spatial_vec)\n",
    "    base_spatial_image_matrix = np.vstack(base_spatial_vec_ls).T\n",
    "    return base_spatial_image_matrix\n",
    "\n",
    "\n",
    "def compute_X(\n",
    "    template,\n",
    "    kernel_size,\n",
    "    gauss_sig_ls,\n",
    "    poly_deg_ls,\n",
    "    kernel_spatial_deg: int = 0,\n",
    "    background_spatial_deg: int = 0,\n",
    "):\n",
    "    # spatial expansion\n",
    "    Nx, Ny = template.shape[1], template.shape[0]\n",
    "    xx_norm, yy_norm = compute_xy_grids(Nx, Ny)\n",
    "    xx_norm /= Nx\n",
    "    yy_norm /= Ny\n",
    "\n",
    "    # compute base image matrix\n",
    "    kernel_bases = compute_kernel_bases(kernel_size, gauss_sig_ls, poly_deg_ls)\n",
    "    base_image_matrix = compute_base_image_matrix(template, kernel_bases)\n",
    "    # compute spatial image matrix\n",
    "    kernel_spatial_image_matrix = compute_spatial_image_matrix(\n",
    "        xx_norm, yy_norm, kernel_spatial_deg, verbose=False\n",
    "    )\n",
    "    background_spatial_image_matrix = compute_spatial_image_matrix(\n",
    "        xx_norm, yy_norm, background_spatial_deg, verbose=False\n",
    "    )\n",
    "    # compute base spatial image matrix\n",
    "    base_spatial_image_matrix = compute_base_spatial_image_matrix(\n",
    "        base_image_matrix, kernel_spatial_image_matrix\n",
    "    )\n",
    "    # compute X\n",
    "    X = np.concatenate(\n",
    "        (base_spatial_image_matrix, background_spatial_image_matrix), axis=1\n",
    "    )\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd778b-e6ea-4aff-ab9c-4ad468be4e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def al_python(\n",
    "    science_image_array, #: np.ndarray,\n",
    "    template_image_array, #: np.ndarray,\n",
    "    x_stars: Sequence[float],\n",
    "    y_stars: Sequence[float],\n",
    "    stamp_size: int = 51,\n",
    "    gauss_sig_ls: Sequence[float] = (0.75, 1.5, 3.0),\n",
    "    poly_deg_ls: Sequence[int] = (2, 2, 2),\n",
    "    kernel_size: int = 31,\n",
    "    kernel_spatial_deg: int = 0,\n",
    "    kernel_background_deg: int = 0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement fitting and convolution in Python (numpy, scipy, sklearn)\n",
    "    \n",
    "    science and template image arrays must already be aligned.\n",
    "    \n",
    "    x_stars, y_stars: x, y positions of objects to use to fit kernel.\n",
    "    stamp_size: size of the stamp around each object to extract.\n",
    "        In the current Science Pipelines equivalent this is done as the footprint of the object.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Making X array\")\n",
    "    X = compute_X(\n",
    "        template_image_array,\n",
    "        kernel_size,\n",
    "        gauss_sig_ls,\n",
    "        poly_deg_ls,\n",
    "        kernel_spatial_deg,\n",
    "        background_spatial_deg,\n",
    "    )\n",
    "\n",
    "    print(\"Fitting\")\n",
    "    sci_vec = science_image_array.flatten()\n",
    "    lin = linear_model.LinearRegression()\n",
    "    lin.fit(X, sci_vec)\n",
    "\n",
    "    sci_pred = lin.predict(X)\n",
    "\n",
    "    return sci_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a4dd3-a023-45f2-b232-44fc6323c3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Subtract template image from image referred to by data_id and run detection.\n",
    "\"\"\"\n",
    "science = butler.get(\"calexp\", science_dr.dataId)\n",
    "source_catalog = butler.get(\"src\", dataId=science_dr.dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af8494-2bd4-4c09-b1df-e673d02ece0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# template = single_image_template\n",
    "template = deep_coadd_template.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2d650-dcf3-4e49-9ac9-6ddc84f12460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx = science.getWidth()\n",
    "ny = science.getHeight()\n",
    "# nx, ny = 125, 125\n",
    "\n",
    "template_x0 = template.getX0()\n",
    "template_y0 = template.getY0()\n",
    "template_image_array = template.image.array[\n",
    "    0-template_x0:nx-template_x0,\n",
    "    0-template_y0:ny-template_y0,\n",
    "]\n",
    "\n",
    "science_x0 = science.getX0()\n",
    "science_y0 = science.getY0()\n",
    "science_image_array = science.image.array[\n",
    "    0-science_x0:nx-science_x0,\n",
    "    0-science_y0:ny-science_y0,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58c6d1-d88b-477c-b440-0f558ad43832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trying to make a block sparse matrix for the footprings\n",
    "from scipy.sparse import bsr_matrix, coo_array, dok_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd4976-f9f1-4a3a-81b8-8d360102c793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sparse_stamps(\n",
    "    image: lsst.afw.image.ExposureF,\n",
    "    source_catalog: [lsst.afw.table.SourceCatalog, astropy.table.Table],\n",
    "    stamp_size: int = 50,\n",
    "):\n",
    "    \"Returns stamps as a sparse matrix\"\n",
    "\n",
    "    M, N = science_image_array.shape\n",
    "\n",
    "    template_stamps = dok_array((M, N), np.float32)\n",
    "\n",
    "    # Reject objects too close to the edge\n",
    "    x_stars = source_catalog[\"slot_Centroid_x\"]\n",
    "    y_stars = source_catalog[\"slot_Centroid_y\"]\n",
    "    (w,) = np.where(\n",
    "        (stamp_size < x_stars)\n",
    "        & (x_stars < M - stamp_size)\n",
    "        & (stamp_size < y_stars)\n",
    "        & (y_stars < N - stamp_size)\n",
    "    )\n",
    "    x_stars = x_stars[w]\n",
    "    y_stars = y_stars[w]\n",
    "    \n",
    "    # Build the collection of stamps\n",
    "    for x, y in zip(x_stars, y_stars):\n",
    "        template_stamps[\n",
    "            int(x - stamp_size // 2), int(y + stamp_size // 2)\n",
    "        ] = template_image_array[int(x - stamp_size // 2), int(y + stamp_size // 2)]\n",
    "\n",
    "    return template_stamps, x_stars, y_stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abaf3a-3a5f-4582-9c4b-a7061012c835",
   "metadata": {},
   "source": [
    "### Sparse stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c4fe4-9c40-4579-9649-f9756b17d821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_sparse_stamps, x_stars, y_stars = build_sparse_stamps(template, source_catalog)\n",
    "science_sparse_stamps, x_stars, y_stars = build_sparse_stamps(science, source_catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c142990-249c-4f6e-9e4b-5584f2a21a71",
   "metadata": {},
   "source": [
    "Fit for the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53753ccc-a6f8-43ab-ad3b-854b64193f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gauss_sig_ls = [0.75, 1.5, 3.0]\n",
    "poly_deg_ls = [2, 2, 2]\n",
    "kernel_size = 31\n",
    "# spatial degree of freedom\n",
    "kernel_spatial_deg = 2\n",
    "background_spatial_deg = 0\n",
    "\n",
    "print(\"Making X array\")\n",
    "\n",
    "X = compute_X(template_sparse_stamps, kernel_size, gauss_sig_ls, poly_deg_ls,\n",
    "    kernel_spatial_deg=0, background_spatial_deg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a43edd-0551-40a2-bbc0-65d4da104384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sci_vec = s_stamp.flatten()\n",
    "lin = linear_model.LinearRegression()\n",
    "lin.fit(X, sci_vec)\n",
    "lin_fits.append(lin)\n",
    "\n",
    "    \n",
    "# Coefficiencts stored in lin.coef_\n",
    "# Now fit for spatial variation of these coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ff17a-affc-4dc9-b085-3d978d3516ac",
   "metadata": {},
   "source": [
    "### Stack stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d44296b-3f33-482b-b209-9d05766007ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_stack_stamps(\n",
    "    image: lsst.afw.image.ExposureF,\n",
    "    source_catalog: Union[lsst.afw.table.SourceCatalog, astropy.table.Table],\n",
    "    stamp_size: int = 50,\n",
    ") -> [np.ndarray, Sequence[float], Sequence[float]]:\n",
    "    \"Returns stamps, x, y as a 3D array\"\n",
    "    stamp_size = 50\n",
    "\n",
    "    image_x0 = image.getX0()\n",
    "    image_y0 = image.getY0()\n",
    "    N = image.getWidth() - image_x0\n",
    "    M = image.getHeight() - image_y0\n",
    "\n",
    "    x_stars = source_catalog[\"slot_Centroid_x\"]\n",
    "    y_stars = source_catalog[\"slot_Centroid_y\"]\n",
    "    (w,) = np.where(\n",
    "        (stamp_size < x_stars)\n",
    "        & (x_stars < M - stamp_size)\n",
    "        & (stamp_size < y_stars)\n",
    "        & (y_stars < N - stamp_size)\n",
    "    )\n",
    "    x_stars = x_stars[w]\n",
    "    y_stars = y_stars[w]\n",
    "\n",
    "    image_stamps = np.empty(\n",
    "        shape=(stamp_size, stamp_size, len(x_stars)), dtype=np.float32\n",
    "    )\n",
    "    for i, (x, y) in enumerate(zip(x_stars, y_stars)):\n",
    "        image_stamps[:, :, i] = image.image.array[\n",
    "            int(image_x0 + x - stamp_size // 2) : int(image_x0 + x + stamp_size // 2),\n",
    "            int(image_y0 + y - stamp_size // 2) : int(image_y0 + y + stamp_size // 2),\n",
    "        ]\n",
    "\n",
    "    return image_stamps, x_stars, y_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93d488-9086-4b57-9901-e49c39895528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_stamps, x_stars, y_stars = build_stack_stamps(template, source_catalog)\n",
    "science_stamps, x_stars, y_stars = build_stack_stamps(science, source_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30e364-ce02-498d-8879-dd26f3a01584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gauss_sig_ls = [0.75, 1.5, 3.0]\n",
    "poly_deg_ls = [2, 2, 2]\n",
    "kernel_size = 31\n",
    "# spatial degree of freedom\n",
    "kernel_spatial_deg = 2\n",
    "background_spatial_deg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011f888-a621-4786-88b8-f9362170f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(x_stars, y_stars)):\n",
    "    t_stamp = template_stamps[:, :, i]\n",
    "    s_stamp = science_stamps[:, :, i]\n",
    "    X = compute_X(t_stamp, kernel_size, gauss_sig_ls, poly_deg_ls,\n",
    "        kernel_spatial_deg=0, background_spatial_deg=0)\n",
    "    sci_vec = s_stamp.flatten()\n",
    "    lin = linear_model.LinearRegression()\n",
    "    lin.fit(X, sci_vec)\n",
    "    lin_fits.append(lin)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574e605-6fab-4160-ab1e-66d21b02cdf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Making X array\")\n",
    "lin_fits = []\n",
    "for i, (x, y) in enumerate(zip(x_stars, y_stars)):\n",
    "    t_stamp = template_stamps[:, :, i]\n",
    "    s_stamp = science_stamps[:, :, i]\n",
    "    X = compute_X(t_stamp, kernel_size, gauss_sig_ls, poly_deg_ls,\n",
    "        kernel_spatial_deg=0, background_spatial_deg=0)\n",
    "    sci_vec = s_stamp.flatten()\n",
    "    lin = linear_model.LinearRegression()\n",
    "    lin.fit(X, sci_vec)\n",
    "    lin_fits.append(lin)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a34b1-1489-47b2-bee8-168e3c793532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coefficiencts stored in lin.coef_\n",
    "# Now fit for spatial variation of these coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994a510-b5d9-4468-9a8e-3f8cee78402b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir(lin_fits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1748379-bbe4-45c1-9cf3-d24bdb91653a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lin_fits[0].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d028340-d01e-4859-b71a-4b23c4908e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lin.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec3c73-6cf5-44ac-baee-4b4479a7e1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sci_pred = lin.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d312fd-5b6c-4f9b-8830-609da762da7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(template_image_array, vmin=-2, vmax=+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208274b-95f0-4267-91e9-4211b6dc07f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(sci_pred.reshape(nx, ny), vmin=-200, vmax=+400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27ee40-0c57-4376-af0d-f96c6753a4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(science_image_array - sci_pred.reshape(nx, ny), vmin=-200, vmax=+400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28a190-9e3e-4f4d-bb84-fb40ff052a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModifiedAlardLuptonSubtractConfig(AlardLuptonSubtractConfig):\n",
    "    pass\n",
    "\n",
    "class ModifiedAlardLuptonSubtractTask(AlardLuptonSubtractTask):\n",
    "    ConfigClass = ModifiedAlardLuptonSubtractConfig\n",
    "    _DefaultName = \"modifiedAlardLuptonSubtract\"\n",
    "    \n",
    "    # `run` calls `runConvolveTemplate` if the template PSF is better\n",
    "    # Let's develop this example first before covering the `runConvolveScience` function.\n",
    "    def runConvolveTemplate(self, template, science, selectSources):\n",
    "        \"\"\"Convolve the template image with a PSF-matching kernel and subtract\n",
    "        from the science image.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        template : `lsst.afw.image.ExposureF`\n",
    "            Template exposure, warped to match the science exposure.\n",
    "        science : `lsst.afw.image.ExposureF`\n",
    "            Science exposure to subtract from the template.\n",
    "        selectSources : `lsst.afw.table.SourceCatalog`\n",
    "            Identified sources on the science exposure. This catalog is used to\n",
    "            select sources in order to perform the AL PSF matching on stamp\n",
    "            images around them.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        results : `lsst.pipe.base.Struct`\n",
    "\n",
    "            ``difference`` : `lsst.afw.image.ExposureF`\n",
    "                Result of subtracting template and science.\n",
    "            ``matchedTemplate`` : `lsst.afw.image.ExposureF`\n",
    "                Warped and PSF-matched template exposure.\n",
    "            ``backgroundModel`` : `lsst.afw.math.Function2D`\n",
    "                Background model that was fit while solving for the PSF-matching kernel\n",
    "            ``psfMatchingKernel`` : `lsst.afw.math.Kernel`\n",
    "                Kernel used to PSF-match the template to the science image.\n",
    "        \"\"\"\n",
    "        # Just some quick debugging to demonstrate that we are running the modifiedAlardLuptonSubtract\n",
    "        self.log.info(\"Running Modified Subtraction Task\")\n",
    "        kernelSources = self.makeKernel.selectKernelSources(template, science,\n",
    "                                                            candidateList=selectSources,\n",
    "                                                            preconvolved=False)\n",
    "        kernelResult = self.makeKernel.run(template, science, kernelSources,\n",
    "                                           preconvolved=False)\n",
    "\n",
    "        # https://github.com/lsst/ip_diffim/blob/main/python/lsst/ip/diffim/subtractImages.py#L564\n",
    "#         matchedTemplate = self._convolveExposure(template, kernelResult.psfMatchingKernel,\n",
    "#                                                  self.convolutionControl,\n",
    "#                                                  bbox=science.getBBox(),\n",
    "#                                                  psf=science.psf,\n",
    "#                                                  photoCalib=science.photoCalib)\n",
    "        \n",
    "        # Get the ndarray\n",
    "        # Get the same BBox because our template might have intentional padding.\n",
    "        # (because we're going to convolve it)\n",
    "    \n",
    "        nx = science.getWidth()\n",
    "        ny = science.getHeight()\n",
    "    \n",
    "        template_x0 = template.getX0()\n",
    "        template_y0 = template.getY0()\n",
    "        template_array = template.image.array[0-template_x0:nx-template_x0,\n",
    "                                              0-template_y0:ny-template_y0]\n",
    "\n",
    "        science_x0 = science.getX0()\n",
    "        science_y0 = science.getY0()\n",
    "        science_array = science.image.array[0-science_x0:nx-science_x0,\n",
    "                                            0-science_y0:ny-science_y0]\n",
    "\n",
    "        sci_pred = new_algorithm(science_array, template_array)\n",
    "        \n",
    "        # Create an exposure object to hold the array\n",
    "        matchedTemplate = template.clone()\n",
    "        matchedTemplate.setPsf(science.psf)\n",
    "        matchedTemplate.setPhotoCalib(science.photoCalib)\n",
    "        convolvedImage = lsst.afw.image.MaskedImageF(template.getBBox())\n",
    "        convolvedImage.array = sci_pred.reshape(template.image.array.shape)\n",
    "        matchedTemplate.setMaskedImage(convolvedImage)\n",
    "\n",
    "        # The actual subtraction is very simple once we have the matchedTemplate and backgroundModel\n",
    "        # It's so simple that it is a free function (that we imported above)\n",
    "        difference = _subtractImages(science, matchedTemplate,\n",
    "                                     backgroundModel=(kernelResult.backgroundModel\n",
    "                                                      if self.config.doSubtractBackground else None))\n",
    "\n",
    "        correctedExposure = self.finalize(template, science, difference,\n",
    "                                          kernelResult.psfMatchingKernel,\n",
    "                                          templateMatched=True)\n",
    "\n",
    "        return lsst.pipe.base.Struct(difference=correctedExposure,\n",
    "                                     matchedTemplate=matchedTemplate,\n",
    "                                     matchedScience=science,\n",
    "                                     backgroundModel=kernelResult.backgroundModel,\n",
    "                                     psfMatchingKernel=kernelResult.psfMatchingKernel)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb98f19-0a41-4773-92dc-e64f51539848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subtract_config = AlardLuptonSubtractConfig()\n",
    "subtract_config.makeKernel.retarget(ModifiedMakeKernelTask, ConfigClass=ModifiedMakeKernelConfig)\n",
    "task = AlardLuptonSubtractTask(config=subtract_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d674fe-a052-44c1-974b-213994e69dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modified_subtract_config = ModifiedAlardLuptonSubtractConfig()\n",
    "modified_task = ModifiedAlardLuptonSubtractTask(config=modified_subtract_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb24bb1-5009-4bfa-887f-df2b49e7c4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modified_subtract_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd095e-e12a-4ea9-9d9f-e08e0850a720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subtraction = subtract(science, template, source_catalog, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a16ab-bb04-4528-bdc9-8ca7c2683f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modified_subtraction = subtract(science, template, source_catalog, task=modified_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3f1c0-fded-4faf-bb09-48cc3cb62a5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T03:19:13.321581Z",
     "iopub.status.busy": "2023-06-13T03:19:13.320680Z",
     "iopub.status.idle": "2023-06-13T03:19:13.326122Z",
     "shell.execute_reply": "2023-06-13T03:19:13.325284Z",
     "shell.execute_reply.started": "2023-06-13T03:19:13.321549Z"
    },
    "tags": []
   },
   "source": [
    "Memory usage grows to ~15 GB and then kernel gets killed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb8b6d-4143-4dd0-86e6-f0a97019e510",
   "metadata": {},
   "source": [
    "I don't know why we don't get log messages from the modified task.  There's more to learn about logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe0fc7-391f-428f-8742-e4953f039b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16b98b-ac70-4967-8b29-a0a258736770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_image_on_wcs(template, vmin=-1, vmax=+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92878e2-57c1-4065-9fa6-ea9bdf8bcb38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_image_on_wcs(science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7bbaa-0acb-4feb-bb59-91a9fbf8786d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_image_on_wcs(modified_subtraction.difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d885f-01a5-42ff-9ec4-7135174df12e",
   "metadata": {},
   "source": [
    "The negative regions above are saturated stars, as indicated by the masked-image view below where \"green\" is saturated.he negative regions above are saturated stars, as indicated by the masked-image view below where \"green\" is saturated.\n",
    "\n",
    "Interpreting the above image plane correctly requires marking the saturated regions.  Stars brighter than ~17th mag will saturate in LSST images.  This means that the recording counts are not propotional to the flux, so the subtraction between two images of that field will not yield clean subtractions of the stars.  In general in one of the images the stars will be a little more saturated than the other and so have fewer proporational counts.  In this case for DC2, , it's the template image that has slightly more saturated stars (due to a higher sky brightness or a sharper PSF FWHM).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3a43c-92be-4eb7-b33c-36a0dc7c33e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display = show_image_with_mask_plane(subtraction.difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace8a62-34c8-405e-a74d-15c145c1d3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Mask plane bit definitions:\\n\", display.getMaskPlaneColor())\n",
    "print(\"\\nMask plane methods:\\n\")\n",
    "help(display.setMaskPlaneColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e7819-b48b-4845-a5e2-3e622b8ed585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detection_catalog = detect(science, modified_subtraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5141fd2-2fb3-42ff-b073-b2ae92262254",
   "metadata": {},
   "source": [
    "## DIA Source Catalog\n",
    "\n",
    "We can getting a better sense of the true performance of the image subtraction by looking at the catalog of detected and measured sources, the DIA Source Cstalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89add2b5-46f7-4672-82ec-34d60f247064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dia_src = detection_catalog.diaSources.asAstropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435968ab-1b77-4666-8c63-a6d4f37862cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specific list.  But \"base_PixelFlags_flag\" should be set for any of these\n",
    "full_list_pixelflags_indicating_bad_source = [\"base_PixelFlags_flag_saturated\",\n",
    "\"base_PixelFlags_flag_saturatedCenter\",\n",
    "\"base_PixelFlags_flag_suspect\",\n",
    "\"base_PixelFlags_flag_suspectCenter\",\n",
    "\"base_PixelFlags_flag_offimage\",\n",
    "\"base_PixelFlags_flag_edge\",\n",
    "\"base_PixelFlags_flag_bad\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d691412-4264-47b3-b4fb-4026a612afb0",
   "metadata": {},
   "source": [
    "There seem to be objects with some of the above flags set, but where \"base_PixelFlags_flag\" is not set.  Investigate.  This is a bug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505947e-7aac-425c-9e72-a949ab7a2990",
   "metadata": {},
   "source": [
    "Apply flags that marker things that pipeline is indicating might be real transients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f756a-5a75-49be-adc9-7d8c2d4ebb2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flags_indicating_bad_source = [\"base_PixelFlags_flag_saturated\",\n",
    "                               \"base_PixelFlags_flag_saturatedCenter\",\n",
    "                               \"base_PixelFlags_flag_suspect\",\n",
    "                               \"base_PixelFlags_flag_suspectCenter\",\n",
    "                               \"base_PixelFlags_flag_offimage\",\n",
    "                               \"base_PixelFlags_flag_edge\",\n",
    "                               \"base_PixelFlags_flag_bad\",\n",
    "                               \"base_SdssShape_flag\",\n",
    "                               \"ip_diffim_DipoleFit_flag_classification\",\n",
    "                               \"ip_diffim_DipoleFit_flag_classificationAttempted\",\n",
    "                               \"base_GaussianFlux_flag\",\n",
    "                               \"slot_Shape_flag\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78068003-58f8-4ba2-b950-7e9a0c494e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad = [dia_src[flag] for flag in flags_indicating_bad_source]\n",
    "bad = np.any(np.vstack(bad), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5813250-e02b-443b-9362-20aa5f881f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_dia_src = dia_src[~bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a155d6-49b1-480d-a5c1-fade0456655e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Found {len(good_dia_src)} good DIA sources out of {len(dia_src)} DIA sources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ae4c2-26c0-4ad9-98f6-c03cd207edcc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "shape_flags = [c for c in good_dia_src.columns if re.search(\"base.*Shape.*_.*flag\", c)]\n",
    "sdss_flags = [c for c in good_dia_src.columns if re.search(\"base.*Sdss.*_.*flag\", c)]\n",
    "slot_flags = [c for c in good_dia_src.columns if re.search(\"slot_.*flag\", c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d71cb3-f9e1-4494-9bf9-27fef5d3d5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = good_dia_src[\"slot_Shape_x\"]\n",
    "y = good_dia_src[\"slot_Shape_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da092954-66eb-4ce0-8d68-423d121cea65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_dia_src[[\"slot_PsfFlux_instFlux\", \"ip_diffim_forced_PsfFlux_instFlux\", \"ip_diffim_forced_PsfFlux_instFluxErr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840fbe6-9b48-474b-ab0a-143dc3c5dbe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(good_dia_src) >= 1:\n",
    "    i = 0\n",
    "\n",
    "    show_image_on_wcs(subtraction.matchedTemplate, x=x[i], y=y[i], stamp_size=100)\n",
    "\n",
    "    show_image_on_wcs(subtraction.matchedScience, x=x[i], y=y[i], stamp_size=100)\n",
    "\n",
    "    show_image_on_wcs(subtraction.difference, x=x[i], y=y[i], stamp_size=100)\n",
    "\n",
    "    geom.Extent2I(100, 100)\n",
    "\n",
    "    center = geom.SpherePoint(good_dia_src[\"coord_ra\"][i], good_dia_src[\"coord_dec\"][i], geom.radians)\n",
    "    extent = geom.Extent2I(100, 100)\n",
    "    cutout = subtraction.difference.getCutout(center, extent)\n",
    "\n",
    "    show_image_with_mask_plane(cutout)\n",
    "\n",
    "    good_dia_src[i][slot_flags]\n",
    "\n",
    "    flags = [c for c in good_dia_src.columns if re.search(\"_flag\", c)]\n",
    "\n",
    "    good_dia_src[flags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d1c36-242d-4f6d-9d64-987bf0fbaf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
